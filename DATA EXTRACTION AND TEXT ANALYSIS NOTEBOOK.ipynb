{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Analysis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from textstat.textstat import textstatistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Importing input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Input.csv')[['URL_ID','URL']]\n",
    "df=df.iloc[0:114]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents=[]\n",
    "for url in df['URL']:\n",
    "    headers={'User-Agent': 'Chrome/74.0.3729.169'}\n",
    "    #The User-Agent request header lets servers and network peers identify the application, operating system, vendor, and/or version of the requesting user agent.\n",
    "    try:\n",
    "        page=requests.get(url, headers=headers) #loading text\n",
    "        print(page)\n",
    "        soup=BeautifulSoup(page.content,'html.parser') #parsing text \n",
    "        title=soup.findAll('h1') #extracting title of website\n",
    "        title=title[0].text\n",
    "        body=soup.findAll(attrs={'class':'td-post-content'}) #extracting required content\n",
    "        body=body[0].text.replace('\\xa0',\"  \").replace('\\n',\"  \") #extract text from p tags and replace end line symbols with space\n",
    "        text=title+ '. '+body #merging title and content\n",
    "        contents.append(text)\n",
    "    except:\n",
    "        contents.append(None)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(df, pd.DataFrame(contents), left_index = True, right_index = True, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['URL_ID', 'URL', 'Text_Contents']\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('collected_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114 entries, 0 to 113\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     114 non-null    int64  \n",
      " 1   URL_ID         114 non-null    float64\n",
      " 2   URL            114 non-null    object \n",
      " 3   Text_Contents  111 non-null    object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 3.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Output.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Text_Contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>AI in healthcare to Improve Patient Outcomes. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>What if the Creation is Taking Over the Creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>What Jobs Will Robots Take From Humans in The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>Will Machine Replace The Human in the Future o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>Will AI Replace Us or Work With Us?.   “Machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146.0</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>Blockchain for Payments.   Reconciling with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147.0</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>The future of Investing.   What Is an Investme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148.0</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>Big Data Analytics in Healthcare.   Quality an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149.0</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>Business Analytics In The Healthcare Industry....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150.0</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>Challenges and Opportunities of Big Data in He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0      37.0  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1      38.0  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2      39.0  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3      40.0  https://insights.blackcoffer.com/will-machine-...   \n",
       "4      41.0  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109   146.0  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110   147.0  https://insights.blackcoffer.com/the-future-of...   \n",
       "111   148.0  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112   149.0  https://insights.blackcoffer.com/business-anal...   \n",
       "113   150.0  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "                                         Text_Contents  \n",
       "0    AI in healthcare to Improve Patient Outcomes. ...  \n",
       "1    What if the Creation is Taking Over the Creato...  \n",
       "2    What Jobs Will Robots Take From Humans in The ...  \n",
       "3    Will Machine Replace The Human in the Future o...  \n",
       "4    Will AI Replace Us or Work With Us?.   “Machin...  \n",
       "..                                                 ...  \n",
       "109  Blockchain for Payments.   Reconciling with th...  \n",
       "110  The future of Investing.   What Is an Investme...  \n",
       "111  Big Data Analytics in Healthcare.   Quality an...  \n",
       "112  Business Analytics In The Healthcare Industry....  \n",
       "113  Challenges and Opportunities of Big Data in He...  \n",
       "\n",
       "[114 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Cleaning StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all Stopwords\n",
    "stop_words = []\n",
    "\n",
    "StopWords_Auditor = 'StopWords/StopWords_Auditor.txt'\n",
    "for stop_word in open(StopWords_Auditor, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip().upper())\n",
    "\n",
    "StopWords_Currencies = 'Stopwords/StopWords_Currencies.txt'\n",
    "for stop_word in open(StopWords_Currencies, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip().upper())\n",
    "\n",
    "StopWords_Generic = 'Stopwords/StopWords_Generic.txt'\n",
    "for stop_word in open(StopWords_Generic, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip().upper())\n",
    "\n",
    "StopWords_GenericLong = 'Stopwords/StopWords_GenericLong.txt'\n",
    "for stop_word in open(StopWords_GenericLong, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip().upper())\n",
    "\n",
    "StopWords_DatesandNumbers= 'Stopwords/StopWords_DatesandNumbers.txt'\n",
    "for stop_word in open(StopWords_DatesandNumbers, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip().upper())\n",
    "\n",
    "StopWords_Geographic= 'Stopwords/StopWords_Geographic.txt'\n",
    "for stop_word in open(StopWords_Geographic, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip().upper())\n",
    "    \n",
    "StopWords_Names= 'Stopwords/StopWords_Names.txt'\n",
    "for stop_word in open(StopWords_Names, 'r').readlines():\n",
    "    stop_words.append(stop_word.rstrip().upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to remove stopwords and tokenize the text data\n",
    "def text_prep(x: str) -> list:\n",
    "     operation = str(x).upper()\n",
    "     operation= re.sub('[^a-zA-Z]+',' ', operation).strip() \n",
    "     tokens = word_tokenize(operation)\n",
    "     words = [t for t in tokens if t not in stop_words]\n",
    "     return words\n",
    "# Applying the function on the data\n",
    "tokenized_text = [text_prep(i) for i in df['Text_Contents']]\n",
    "df[\"tokenized_text\"] = tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['tokenized_text'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Creating a dictionary of Positive and Negative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing master Dictionary\n",
    "positive_dict=[]\n",
    "positive= 'MasterDictionary/positive-words.txt'\n",
    "for word in open(positive, 'r').readlines():\n",
    "    positive_dict.append(word.rstrip().upper())\n",
    "\n",
    "negative_dict=[]\n",
    "negative= 'MasterDictionary/negative-words.txt'\n",
    "for word in open(negative, 'r').readlines():\n",
    "    negative_dict.append(word.rstrip().upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_master=[words for words in positive_dict if words not in stop_words]\n",
    "negative_master=[words for words in negative_dict if words not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Extracting Derived Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive Score\n",
    "num_pos = df[\"tokenized_text\"].map(lambda x: len([i for i in x if i in positive_master]))\n",
    "df[\"positive_score\"] = num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative Score\n",
    "num_neg = df[\"tokenized_text\"].map(lambda x: len([i for i in x if i in negative_master]))\n",
    "df[\"negative_score\"] = num_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Polarity Score\n",
    "df['polarity_score'] = round((df['positive_score'] - df['negative_score'])/(df['positive_score'] + df['negative_score'] + 0.000001), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subjectivity Score\n",
    "df['subjectivity_score'] = round((df['positive_score'] + df['negative_score'])/(df['num_words'] + 0.000001), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Analysis of Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Average Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Sentence Length\n",
    "df['num_sent'] = df['Text_Contents'].map(lambda x: len(sent_tokenize(x)), na_action='ignore')\n",
    "df['avg_sent_len'] = round(df['num_words']/df['num_sent'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Percentage of Complex Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllables_count(text):\n",
    "  return textstatistics().syllable_count(text)\n",
    "  \n",
    "def complex_words(text):\n",
    "  words_set = set()\n",
    "  words = text\n",
    "  for word in words:\n",
    "    syllable_count = syllables_count(word)\n",
    "    if syllable_count > 2:\n",
    "      words_set.add(word)\n",
    "  return len(words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['complex_words'] = df['tokenized_text'].apply(lambda x: complex_words(x))\n",
    "df['complex_words_percent'] = round((df['complex_words']/df['num_words']), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Fog Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fog_index'] = 0.4 * (df['avg_sent_len'] + df['complex_words_percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Average Number of Words per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_words_per_sent'] = round(df['num_words']/df['num_sent'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Complex Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already calculated in complex_words Column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Word Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already calculated in num_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(The library being used by default handles exceptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['syll_count'] = df['tokenized_text'].apply(lambda x: syllables_count(\" \".join(x)))\n",
    "df['syll_per_word'] = df['syll_count']/df['num_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Personal Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnl_pronoun(text):\n",
    "  pronounRe = re.compile(r'\\b(I|we|my|ours|(?-i:us))\\b',re.I)\n",
    "  allpronouns = pronounRe.findall(text)\n",
    "  return allpronouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(?-i:us) is used as in-line modifier group where the matching is CASE SENSITIVE. As a result, this matches only us not US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['psnl_pronouns'] = df['Text_Contents'].map(lambda x: len(psnl_pronoun(x)), na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_len(text):\n",
    "  text = ''.join(text)\n",
    "  filtered= re.sub('[^a-zA-Z]+',' ', text)\n",
    "  words = [word for word in filtered.split() if word]\n",
    "  avglen = sum(map(len, words))/len(words)\n",
    "  return avglen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_word_len'] = df['Text_Contents'].map(lambda x: text_len(x), na_action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the Output Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['URL_ID', 'URL', 'Text_Contents', 'tokenized_text', 'num_words',\n",
       "       'positive_score', 'negative_score', 'polarity_score',\n",
       "       'subjectivity_score', 'num_sent', 'avg_sent_len', 'complex_words',\n",
       "       'complex_words_percent', 'Fog_index', 'avg_words_per_sent',\n",
       "       'syll_count', 'syll_per_word', 'psnl_pronouns', 'avg_word_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['URL_ID', 'URL', 'positive_score', 'negative_score', 'polarity_score', 'subjectivity_score', 'avg_sent_len', 'complex_words_percent', 'Fog_index', 'avg_words_per_sent', 'complex_words', 'num_words', 'syll_per_word', 'psnl_pronouns', 'avg_word_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5.060</td>\n",
       "      <td>12.42</td>\n",
       "      <td>246</td>\n",
       "      <td>969</td>\n",
       "      <td>2.303406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.566338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>58</td>\n",
       "      <td>37</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.23</td>\n",
       "      <td>2.812</td>\n",
       "      <td>6.79</td>\n",
       "      <td>126</td>\n",
       "      <td>550</td>\n",
       "      <td>2.156364</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.733425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.944</td>\n",
       "      <td>9.59</td>\n",
       "      <td>217</td>\n",
       "      <td>825</td>\n",
       "      <td>2.384242</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.366647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.688</td>\n",
       "      <td>6.52</td>\n",
       "      <td>136</td>\n",
       "      <td>626</td>\n",
       "      <td>2.193291</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.794313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>60</td>\n",
       "      <td>27</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.12</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.24</td>\n",
       "      <td>3.856</td>\n",
       "      <td>9.39</td>\n",
       "      <td>181</td>\n",
       "      <td>751</td>\n",
       "      <td>2.270306</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.028016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0    37.0  https://insights.blackcoffer.com/ai-in-healthc...              66   \n",
       "1    38.0  https://insights.blackcoffer.com/what-if-the-c...              58   \n",
       "2    39.0  https://insights.blackcoffer.com/what-jobs-wil...              65   \n",
       "3    40.0  https://insights.blackcoffer.com/will-machine-...              66   \n",
       "4    41.0  https://insights.blackcoffer.com/will-ai-repla...              60   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0              34            0.32                0.10                 12.4   \n",
       "1              37            0.22                0.17                  6.8   \n",
       "2              35            0.30                0.12                  9.6   \n",
       "3              28            0.40                0.15                  6.5   \n",
       "4              27            0.38                0.12                  9.4   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                         0.25      5.060                             12.42   \n",
       "1                         0.23      2.812                              6.79   \n",
       "2                         0.26      3.944                              9.59   \n",
       "3                         0.22      2.688                              6.52   \n",
       "4                         0.24      3.856                              9.39   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 246         969           2.303406                1.0   \n",
       "1                 126         550           2.156364                7.0   \n",
       "2                 217         825           2.384242                3.0   \n",
       "3                 136         626           2.193291               17.0   \n",
       "4                 181         751           2.270306               16.0   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0         5.566338  \n",
       "1         4.733425  \n",
       "2         5.366647  \n",
       "3         4.794313  \n",
       "4         5.028016  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT', 'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Output-Data-Structure.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0ecf8c9e1fd008d856daa58452e13b85e83f1c5830c4b6d974f353691db55f53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
